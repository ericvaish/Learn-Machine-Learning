## What is Standardization?

It is a **feature scaling technique** used to transform numerical data into standard format. It ensures all features have a **mean of 0 and a standard deviation of 1**, making them comparable.

​
### **Formula for Standardization**
For each feature \( X \), standardization is done using:

X' = (X - μ) / σ

Where:
- **X** = original feature value
- **μ** = mean of the feature
- **σ** = standard deviation of the feature
- **X'** = standardized feature value



### **Why Standardization?**
1. **Improves Model Performance**: Many ML algorithms (like logistic regression, SVM, and neural networks) perform better when features are standardized.
2. **Speeds Up Training**: Gradient descent converges faster when features are on the same scale.
3. **Handles Different Feature Scales**: If features have different scales (e.g., age in years vs. salary in thousands), standardization makes them comparable.
4. **Prevents Bias Towards Larger Magnitude Features**: Some models, like k-NN and SVM, rely on distance calculations, which get skewed by unscaled data.

### **When to Use Standardization?**
- When using algorithms that rely on distance-based calculations (e.g., **KNN, SVM, PCA, K-Means**).
- When using **gradient-based models** (e.g., **logistic regression, neural networks**) to improve convergence speed.